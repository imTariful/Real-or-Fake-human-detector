{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIop1oYQdnmB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import cvzone\n",
        "from time import time\n",
        "from cvzone.FaceDetectionModule import FaceDetector\n",
        "\n",
        "# ========== Configuration ==========\n",
        "CLASS_ID = 0  # 0 = fake, 1 = real\n",
        "OUTPUT_FOLDER = 'Dataset/DataCollect'\n",
        "CONFIDENCE_THRESHOLD = 0.8\n",
        "SAVE_IMAGES = True\n",
        "BLUR_THRESHOLD = 20\n",
        "DEBUG_MODE = False\n",
        "OFFSET_PERCENT_W = 10\n",
        "OFFSET_PERCENT_H = 20\n",
        "CAM_WIDTH, CAM_HEIGHT = 640, 480\n",
        "FLOAT_PRECISION = 6\n",
        "\n",
        "# ========== Ensure Output Folder Exists ==========\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# ========== Webcam Setup ==========\n",
        "cap = cv2.VideoCapture(1)\n",
        "if not cap.isOpened():\n",
        "    cap = cv2.VideoCapture(0)\n",
        "cap.set(3, CAM_WIDTH)\n",
        "cap.set(4, CAM_HEIGHT)\n",
        "\n",
        "# ========== Face Detector Initialization ==========\n",
        "detector = FaceDetector(minDetectionCon=0.5, modelSelection=0)\n",
        "\n",
        "# ========== Main Loop ==========\n",
        "while True:\n",
        "    success, frame = cap.read()\n",
        "    if not success:\n",
        "        print(\"âŒ Camera not working\")\n",
        "        break\n",
        "\n",
        "    img_output = frame.copy()\n",
        "    frame, face_bboxes = detector.findFaces(frame, draw=False)\n",
        "\n",
        "    blur_results = []\n",
        "    annotations = []\n",
        "\n",
        "    if face_bboxes:\n",
        "        for face in face_bboxes:\n",
        "            x, y, w, h = face[\"bbox\"]\n",
        "            detection_score = float(face[\"score\"][0])\n",
        "\n",
        "            if detection_score > CONFIDENCE_THRESHOLD:\n",
        "                # Apply offsets\n",
        "                offset_w = (OFFSET_PERCENT_W / 100) * w\n",
        "                offset_h = (OFFSET_PERCENT_H / 100) * h\n",
        "\n",
        "                x = max(int(x - offset_w), 0)\n",
        "                y = max(int(y - offset_h * 3), 0)\n",
        "                w = max(int(w + offset_w * 2), 0)\n",
        "                h = max(int(h + offset_h * 3.5), 0)\n",
        "\n",
        "                face_img = frame[y:y + h, x:x + w]\n",
        "\n",
        "                if face_img.size > 0:\n",
        "                    cv2.imshow(\"Face\", face_img)\n",
        "\n",
        "                    # Blur detection using Laplacian\n",
        "                    blur_score = int(cv2.Laplacian(face_img, cv2.CV_64F).var())\n",
        "                    blur_results.append(blur_score > BLUR_THRESHOLD)\n",
        "\n",
        "                    # Normalize coordinates for YOLO format\n",
        "                    ih, iw, _ = frame.shape\n",
        "                    xc, yc = x + w / 2, y + h / 2\n",
        "                    xcn = round(xc / iw, FLOAT_PRECISION)\n",
        "                    ycn = round(yc / ih, FLOAT_PRECISION)\n",
        "                    wn = round(w / iw, FLOAT_PRECISION)\n",
        "                    hn = round(h / ih, FLOAT_PRECISION)\n",
        "\n",
        "                    # Ensure normalized values do not exceed 1\n",
        "                    xcn = min(xcn, 1)\n",
        "                    ycn = min(ycn, 1)\n",
        "                    wn = min(wn, 1)\n",
        "                    hn = min(hn, 1)\n",
        "\n",
        "                    # Store annotation info\n",
        "                    annotations.append(f\"{CLASS_ID} {xcn} {ycn} {wn} {hn}\\n\")\n",
        "\n",
        "                    # Draw bounding box and info on output image\n",
        "                    cv2.rectangle(img_output, (x, y, w, h), (255, 0, 0), 3)\n",
        "                    cvzone.putTextRect(\n",
        "                        img_output,\n",
        "                        f'Score: {int(detection_score * 100)}% Blur: {blur_score}',\n",
        "                        (x, y - 10),\n",
        "                        scale=2,\n",
        "                        thickness=2\n",
        "                    )\n",
        "\n",
        "                    if DEBUG_MODE:\n",
        "                        print(f\"Blur Score: {blur_score} - {'Sharp' if blur_score > BLUR_THRESHOLD else 'Blurry'}\")\n",
        "\n",
        "        # Save image and label if all detected faces are sharp\n",
        "        if SAVE_IMAGES and all(blur_results) and blur_results:\n",
        "            timestamp = str(time()).replace('.', '')\n",
        "            img_path = f\"{OUTPUT_FOLDER}/{timestamp}.jpg\"\n",
        "            txt_path = f\"{OUTPUT_FOLDER}/{timestamp}.txt\"\n",
        "\n",
        "            cv2.imwrite(img_path, frame)\n",
        "            with open(txt_path, 'a') as f:\n",
        "                f.writelines(annotations)\n",
        "\n",
        "    # Show output\n",
        "    cv2.imshow(\"Image\", img_output)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# ========== Cleanup ==========\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ]
}
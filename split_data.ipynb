{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIop1oYQdnmB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from itertools import islice\n",
        "\n",
        "# ========== Configuration ==========\n",
        "INPUT_FOLDER = \"Dataset/all\"\n",
        "OUTPUT_FOLDER = \"Dataset/SplitData\"\n",
        "SPLIT_RATIOS = {\"train\": 0.7, \"val\": 0.2, \"test\": 0.1}\n",
        "CLASSES = [\"fake\", \"real\"]\n",
        "\n",
        "# ========== Cleanup Previous Output ==========\n",
        "if os.path.exists(OUTPUT_FOLDER):\n",
        "    shutil.rmtree(OUTPUT_FOLDER)\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "\n",
        "# ========== Create Output Subdirectories ==========\n",
        "for split in SPLIT_RATIOS:\n",
        "    os.makedirs(f\"{OUTPUT_FOLDER}/{split}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{OUTPUT_FOLDER}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "# ========== Collect & Shuffle File Base Names ==========\n",
        "all_files = os.listdir(INPUT_FOLDER)\n",
        "base_names = list(set(name.split('.')[0] for name in all_files))\n",
        "random.shuffle(base_names)\n",
        "\n",
        "# ========== Calculate Split Sizes ==========\n",
        "total_files = len(base_names)\n",
        "len_train = int(total_files * SPLIT_RATIOS[\"train\"])\n",
        "len_val = int(total_files * SPLIT_RATIOS[\"val\"])\n",
        "len_test = total_files - len_train - len_val  # Ensure 100%\n",
        "\n",
        "splits = [len_train, len_val, len_test]\n",
        "split_names = [\"train\", \"val\", \"test\"]\n",
        "split_data = [list(islice(iter(base_names), count)) for count in splits]\n",
        "\n",
        "print(f\"üìä Total: {total_files} files\")\n",
        "print(f\"üìÇ Split: {len_train} train, {len_val} val, {len_test} test\")\n",
        "\n",
        "# ========== Copy Files into Split Folders ==========\n",
        "for i, split_name in enumerate(split_names):\n",
        "    for file_base in split_data[i]:\n",
        "        img_src = os.path.join(INPUT_FOLDER, f\"{file_base}.jpg\")\n",
        "        label_src = os.path.join(INPUT_FOLDER, f\"{file_base}.txt\")\n",
        "        img_dst = os.path.join(OUTPUT_FOLDER, split_name, \"images\", f\"{file_base}.jpg\")\n",
        "        label_dst = os.path.join(OUTPUT_FOLDER, split_name, \"labels\", f\"{file_base}.txt\")\n",
        "\n",
        "        try:\n",
        "            shutil.copy(img_src, img_dst)\n",
        "            shutil.copy(label_src, label_dst)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"‚ö†Ô∏è Skipped missing pair: {file_base}\")\n",
        "\n",
        "print(\"‚úÖ Dataset splitting complete.\")\n",
        "\n",
        "# ========== Create data.yaml for YOLO ==========\n",
        "data_yaml_content = f'''path: .\n",
        "train: train/images\n",
        "val: val/images\n",
        "test: test/images\n",
        "\n",
        "nc: {len(CLASSES)}\n",
        "names: {CLASSES}\n",
        "'''\n",
        "\n",
        "with open(os.path.join(OUTPUT_FOLDER, \"data.yaml\"), 'w') as yaml_file:\n",
        "    yaml_file.write(data_yaml_content)\n",
        "\n",
        "print(\"‚úÖ data.yaml file created.\")\n"
      ]
    }
  ]
}